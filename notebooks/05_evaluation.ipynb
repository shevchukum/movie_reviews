{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bc82d7a-466e-40db-a308-0afc7681845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 1563/1563 [3:53:01<00:00,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.4450\n",
      "Precision: 0.1980\n",
      "Recall: 0.4450\n",
      "F1 Score: 0.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Dima\\anaconda3\\envs\\movie_review_mlm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Testing SST-2 dataset 25K reviews samples \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from tokenizers import Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"The PyTorch API of nested tensors\")\n",
    "\n",
    "# =======================\n",
    "# Load CONFIG\n",
    "# =======================\n",
    "CONFIG = {\n",
    "    \"d_model\": 512,\n",
    "    \"nhead\": 8,\n",
    "    \"num_layers\": 6,\n",
    "    \"dim_feedforward\": 2048,\n",
    "    \"batch_size\": 16,\n",
    "    \"max_seq_len\": 768,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"tokenizer_path\": \"movie_review_tokenizer.json\",\n",
    "    \"model_path\": \"CLS_epoch_62.pt\",\n",
    "    \"test_ids\": \"SST-2/SST_padded_token_ids.pt\",\n",
    "    \"test_attention_masks\": \"SST-2/SST_padded_attention_masks.pt\",\n",
    "    \"test_sentiment\": \"SST-2/SST_sentiment_labels.pt\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# 1. Classification Model Architecture\n",
    "# =======================\n",
    "class HybridClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size=CONFIG[\"d_model\"], num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, token_embeddings):\n",
    "        mean_pool = token_embeddings.mean(dim=1)\n",
    "        cnn_out = self.relu(self.cnn(token_embeddings.transpose(1, 2)))\n",
    "        max_pool = self.pool(cnn_out).squeeze(-1)\n",
    "        concat = torch.cat([mean_pool, max_pool], dim=-1)\n",
    "        return self.classifier(concat)\n",
    "\n",
    "class CustomMLM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if \"vocab_size\" not in config:\n",
    "            tokenizer = Tokenizer.from_file(config[\"tokenizer_path\"])\n",
    "            config[\"vocab_size\"] = tokenizer.get_vocab_size()\n",
    "            \n",
    "        self.embedding = nn.Embedding(config[\"vocab_size\"], config[\"d_model\"])\n",
    "        self.pos_encoder = nn.Embedding(config[\"max_seq_len\"], config[\"d_model\"])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"d_model\"],\n",
    "            nhead=config[\"nhead\"],\n",
    "            dim_feedforward=config[\"dim_feedforward\"],\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config[\"num_layers\"])\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        seq_len = input_ids.size(1)\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        embeddings = self.embedding(input_ids) + self.pos_encoder(positions)\n",
    "        embeddings = self.encoder(embeddings, src_key_padding_mask=~attention_mask.bool())\n",
    "        return embeddings\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, mlm_model):\n",
    "        super().__init__()\n",
    "        self.mlm = mlm_model\n",
    "        self.head = HybridClassificationHead()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.mlm(input_ids, attention_mask)\n",
    "        return self.head(embeddings)\n",
    "\n",
    "# =======================\n",
    "# 2. Load model and data\n",
    "# =======================\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, token_ids, attention_mask, labels):\n",
    "        self.token_ids = token_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.token_ids[idx].long(),\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx].clone().detach().long(),\n",
    "        }\n",
    "\n",
    "# Loading model\n",
    "mlm_model = CustomMLM(CONFIG).to(CONFIG[\"device\"])\n",
    "model = SentimentClassifier(mlm_model).to(CONFIG[\"device\"])\n",
    "model.load_state_dict(torch.load(CONFIG[\"model_path\"], map_location=torch.device(CONFIG[\"device\"])))\n",
    "model.eval()\n",
    "\n",
    "# Loading test dataset\n",
    "test_dataset = SentimentDataset(\n",
    "    torch.load(CONFIG[\"test_ids\"]),  \n",
    "    torch.load(CONFIG[\"test_attention_masks\"]),\n",
    "    torch.load(CONFIG[\"test_sentiment\"])\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"])\n",
    "\n",
    "# =======================\n",
    "# 3. Evaluation\n",
    "# =======================\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(CONFIG[\"device\"])\n",
    "            attention_mask = batch[\"attention_mask\"].to(CONFIG[\"device\"])\n",
    "            labels = batch[\"labels\"].to(CONFIG[\"device\"])\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Evaluate\n",
    "metrics = evaluate_model(model, test_loader)\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caacce45-a61a-4687-887a-4b79faf008ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 1563/1563 [2:08:15<00:00,  4.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.8610\n",
      "Precision: 0.8617\n",
      "Recall: 0.8610\n",
      "F1 Score: 0.8610\n"
     ]
    }
   ],
   "source": [
    "# Testing IMDb dataset 25K reviews\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from tokenizers import Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"The PyTorch API of nested tensors\")\n",
    "\n",
    "# =======================\n",
    "# Load CONFIG\n",
    "# =======================\n",
    "CONFIG = {\n",
    "    \"d_model\": 512,\n",
    "    \"nhead\": 8,\n",
    "    \"num_layers\": 6,\n",
    "    \"dim_feedforward\": 2048,\n",
    "    \"batch_size\": 16,\n",
    "    \"max_seq_len\": 768,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"tokenizer_path\": \"movie_review_tokenizer.json\",\n",
    "    \"model_path\": \"epoch_62.pt\",\n",
    "    \"test_ids\": \"IMDb/padded_token_ids_test.pt\",\n",
    "    \"test_attention_masks\": \"IMDb/padded_attention_masks_test.pt\",\n",
    "    \"test_sentiment\": \"IMDb/sentiment_labels_test.pt\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# 1. Classification Model Architecture\n",
    "# =======================\n",
    "class HybridClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size=CONFIG[\"d_model\"], num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, token_embeddings):\n",
    "        mean_pool = token_embeddings.mean(dim=1)\n",
    "        cnn_out = self.relu(self.cnn(token_embeddings.transpose(1, 2)))\n",
    "        max_pool = self.pool(cnn_out).squeeze(-1)\n",
    "        concat = torch.cat([mean_pool, max_pool], dim=-1)\n",
    "        return self.classifier(concat)\n",
    "\n",
    "class CustomMLM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if \"vocab_size\" not in config:\n",
    "            tokenizer = Tokenizer.from_file(config[\"tokenizer_path\"])\n",
    "            config[\"vocab_size\"] = tokenizer.get_vocab_size()\n",
    "            \n",
    "        self.embedding = nn.Embedding(config[\"vocab_size\"], config[\"d_model\"])\n",
    "        self.pos_encoder = nn.Embedding(config[\"max_seq_len\"], config[\"d_model\"])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"d_model\"],\n",
    "            nhead=config[\"nhead\"],\n",
    "            dim_feedforward=config[\"dim_feedforward\"],\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config[\"num_layers\"])\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        seq_len = input_ids.size(1)\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        embeddings = self.embedding(input_ids) + self.pos_encoder(positions)\n",
    "        embeddings = self.encoder(embeddings, src_key_padding_mask=~attention_mask.bool())\n",
    "        return embeddings\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, mlm_model):\n",
    "        super().__init__()\n",
    "        self.mlm = mlm_model\n",
    "        self.head = HybridClassificationHead()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.mlm(input_ids, attention_mask)\n",
    "        return self.head(embeddings)\n",
    "\n",
    "# =======================\n",
    "# 2. Load model and data\n",
    "# =======================\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, token_ids, attention_mask, labels):\n",
    "        self.token_ids = token_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.token_ids[idx].long(),\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx].clone().detach().long(),\n",
    "        }\n",
    "\n",
    "# Loading model\n",
    "mlm_model = CustomMLM(CONFIG).to(CONFIG[\"device\"])\n",
    "model = SentimentClassifier(mlm_model).to(CONFIG[\"device\"])\n",
    "model.load_state_dict(torch.load(CONFIG[\"model_path\"], map_location=torch.device(CONFIG[\"device\"])))\n",
    "model.eval()\n",
    "\n",
    "# Loading test dataset\n",
    "test_dataset = SentimentDataset(\n",
    "    torch.load(CONFIG[\"test_ids\"]),  \n",
    "    torch.load(CONFIG[\"test_attention_masks\"]),\n",
    "    torch.load(CONFIG[\"test_sentiment\"])\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"])\n",
    "\n",
    "# =======================\n",
    "# 3. Evaluation\n",
    "# =======================\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(CONFIG[\"device\"])\n",
    "            attention_mask = batch[\"attention_mask\"].to(CONFIG[\"device\"])\n",
    "            labels = batch[\"labels\"].to(CONFIG[\"device\"])\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Evaluate\n",
    "metrics = evaluate_model(model, test_loader)\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c75779c-ad37-44fe-9142-9e374e61d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████| 125/125 [18:06<00:00,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.7715\n",
      "Precision: 0.7868\n",
      "Recall: 0.7715\n",
      "F1 Score: 0.7684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testig MB dataset 2K reviews \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from tokenizers import Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"The PyTorch API of nested tensors\")\n",
    "\n",
    "# =======================\n",
    "# Load CONFIG\n",
    "# =======================\n",
    "CONFIG = {\n",
    "    \"d_model\": 512,\n",
    "    \"nhead\": 8,\n",
    "    \"num_layers\": 6,\n",
    "    \"dim_feedforward\": 2048,\n",
    "    \"batch_size\": 16,\n",
    "    \"max_seq_len\": 768,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"tokenizer_path\": \"movie_review_tokenizer.json\",\n",
    "    \"model_path\": \"epoch_62.pt\",\n",
    "    \"test_ids\": \"MB/MB_padded_token_ids.pt\",\n",
    "    \"test_attention_masks\": \"MB/MB_padded_attention_masks.pt\",\n",
    "    \"test_sentiment\": \"MB/MB_sentiment_labels.pt\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# 1. Classification Model Architecture\n",
    "# =======================\n",
    "class HybridClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size=CONFIG[\"d_model\"], num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, token_embeddings):\n",
    "        mean_pool = token_embeddings.mean(dim=1)\n",
    "        cnn_out = self.relu(self.cnn(token_embeddings.transpose(1, 2)))\n",
    "        max_pool = self.pool(cnn_out).squeeze(-1)\n",
    "        concat = torch.cat([mean_pool, max_pool], dim=-1)\n",
    "        return self.classifier(concat)\n",
    "\n",
    "class CustomMLM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if \"vocab_size\" not in config:\n",
    "            tokenizer = Tokenizer.from_file(config[\"tokenizer_path\"])\n",
    "            config[\"vocab_size\"] = tokenizer.get_vocab_size()\n",
    "            \n",
    "        self.embedding = nn.Embedding(config[\"vocab_size\"], config[\"d_model\"])\n",
    "        self.pos_encoder = nn.Embedding(config[\"max_seq_len\"], config[\"d_model\"])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"d_model\"],\n",
    "            nhead=config[\"nhead\"],\n",
    "            dim_feedforward=config[\"dim_feedforward\"],\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config[\"num_layers\"])\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        seq_len = input_ids.size(1)\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        embeddings = self.embedding(input_ids) + self.pos_encoder(positions)\n",
    "        embeddings = self.encoder(embeddings, src_key_padding_mask=~attention_mask.bool())\n",
    "        return embeddings\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, mlm_model):\n",
    "        super().__init__()\n",
    "        self.mlm = mlm_model\n",
    "        self.head = HybridClassificationHead()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.mlm(input_ids, attention_mask)\n",
    "        return self.head(embeddings)\n",
    "\n",
    "# =======================\n",
    "# 2. Load model and data\n",
    "# =======================\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, token_ids, attention_mask, labels):\n",
    "        self.token_ids = token_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.token_ids[idx].long(),\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx].clone().detach().long(),\n",
    "        }\n",
    "\n",
    "# Loading model\n",
    "mlm_model = CustomMLM(CONFIG).to(CONFIG[\"device\"])\n",
    "model = SentimentClassifier(mlm_model).to(CONFIG[\"device\"])\n",
    "model.load_state_dict(torch.load(CONFIG[\"model_path\"], map_location=torch.device(CONFIG[\"device\"])))\n",
    "model.eval()\n",
    "\n",
    "# Loading test dataset\n",
    "test_dataset = SentimentDataset(\n",
    "    torch.load(CONFIG[\"test_ids\"]),  \n",
    "    torch.load(CONFIG[\"test_attention_masks\"]),\n",
    "    torch.load(CONFIG[\"test_sentiment\"])\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"])\n",
    "\n",
    "# =======================\n",
    "# 3. Evaluation\n",
    "# =======================\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(CONFIG[\"device\"])\n",
    "            attention_mask = batch[\"attention_mask\"].to(CONFIG[\"device\"])\n",
    "            labels = batch[\"labels\"].to(CONFIG[\"device\"])\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Evaluate\n",
    "metrics = evaluate_model(model, test_loader)\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c97e2df5-1c4b-43d4-9410-497f53d69a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████| 1563/1563 [3:58:47<00:00,  9.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "Accuracy: 0.5080\n",
      "Precision: 0.6806\n",
      "Recall: 0.5080\n",
      "F1 Score: 0.3535\n"
     ]
    }
   ],
   "source": [
    "# Testig Amazon dataset 25K reviews \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from tokenizers import Tokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"The PyTorch API of nested tensors\")\n",
    "\n",
    "# =======================\n",
    "# Load CONFIG\n",
    "# =======================\n",
    "CONFIG = {\n",
    "    \"d_model\": 512,\n",
    "    \"nhead\": 8,\n",
    "    \"num_layers\": 6,\n",
    "    \"dim_feedforward\": 2048,\n",
    "    \"batch_size\": 16,\n",
    "    \"max_seq_len\": 768,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"tokenizer_path\": \"movie_review_tokenizer.json\",\n",
    "    \"model_path\": \"epoch_62.pt\",\n",
    "    \"test_ids\": \"Amazon/A_padded_token_ids.pt\",\n",
    "    \"test_attention_masks\": \"Amazon/A_padded_attention_masks.pt\",\n",
    "    \"test_sentiment\": \"Amazon/A_sentiment_labels.pt\"\n",
    "}\n",
    "\n",
    "# =======================\n",
    "# 1. Classification Model Architecture\n",
    "# =======================\n",
    "class HybridClassificationHead(nn.Module):\n",
    "    def __init__(self, hidden_size=CONFIG[\"d_model\"], num_classes=2):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, token_embeddings):\n",
    "        mean_pool = token_embeddings.mean(dim=1)\n",
    "        cnn_out = self.relu(self.cnn(token_embeddings.transpose(1, 2)))\n",
    "        max_pool = self.pool(cnn_out).squeeze(-1)\n",
    "        concat = torch.cat([mean_pool, max_pool], dim=-1)\n",
    "        return self.classifier(concat)\n",
    "\n",
    "class CustomMLM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        if \"vocab_size\" not in config:\n",
    "            tokenizer = Tokenizer.from_file(config[\"tokenizer_path\"])\n",
    "            config[\"vocab_size\"] = tokenizer.get_vocab_size()\n",
    "            \n",
    "        self.embedding = nn.Embedding(config[\"vocab_size\"], config[\"d_model\"])\n",
    "        self.pos_encoder = nn.Embedding(config[\"max_seq_len\"], config[\"d_model\"])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"d_model\"],\n",
    "            nhead=config[\"nhead\"],\n",
    "            dim_feedforward=config[\"dim_feedforward\"],\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config[\"num_layers\"])\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        seq_len = input_ids.size(1)\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        embeddings = self.embedding(input_ids) + self.pos_encoder(positions)\n",
    "        embeddings = self.encoder(embeddings, src_key_padding_mask=~attention_mask.bool())\n",
    "        return embeddings\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, mlm_model):\n",
    "        super().__init__()\n",
    "        self.mlm = mlm_model\n",
    "        self.head = HybridClassificationHead()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.mlm(input_ids, attention_mask)\n",
    "        return self.head(embeddings)\n",
    "\n",
    "# =======================\n",
    "# 2. Load model and data\n",
    "# =======================\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, token_ids, attention_mask, labels):\n",
    "        self.token_ids = token_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.token_ids[idx].long(),\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx].clone().detach().long(),\n",
    "        }\n",
    "\n",
    "# Loading model\n",
    "mlm_model = CustomMLM(CONFIG).to(CONFIG[\"device\"])\n",
    "model = SentimentClassifier(mlm_model).to(CONFIG[\"device\"])\n",
    "model.load_state_dict(torch.load(CONFIG[\"model_path\"], map_location=torch.device(CONFIG[\"device\"])))\n",
    "model.eval()\n",
    "\n",
    "# Loading test dataset\n",
    "test_dataset = SentimentDataset(\n",
    "    torch.load(CONFIG[\"test_ids\"]),  \n",
    "    torch.load(CONFIG[\"test_attention_masks\"]),\n",
    "    torch.load(CONFIG[\"test_sentiment\"])\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"])\n",
    "\n",
    "# =======================\n",
    "# 3. Evaluation\n",
    "# =======================\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(CONFIG[\"device\"])\n",
    "            attention_mask = batch[\"attention_mask\"].to(CONFIG[\"device\"])\n",
    "            labels = batch[\"labels\"].to(CONFIG[\"device\"])\n",
    "            \n",
    "            logits = model(input_ids, attention_mask)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Evaluate\n",
    "metrics = evaluate_model(model, test_loader)\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f7a87-ee19-47a3-8f20-dcaa88b762ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_review_mlm",
   "language": "python",
   "name": "movie_review_mlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
