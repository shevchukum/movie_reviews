{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942316ff-efa2-491c-a4eb-4542b7d2c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tokenizers import Tokenizer\n",
    "from torch.optim import AdamW\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# 0. Configuration\n",
    "# ======================\n",
    "CONFIG = {\n",
    "    # Model Architecture\n",
    "    \"d_model\": 512,\n",
    "    \"nhead\": 8,\n",
    "    \"num_layers\": 6,\n",
    "    \"dim_feedforward\": 2048,\n",
    "    \n",
    "    # Training Parameters\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"epochs\": 24,\n",
    "    \"mask_prob\": 0.15,\n",
    "    \n",
    "    # Data Handling\n",
    "    \"max_seq_len\": 768,\n",
    "    \"train_ratio\": 0.9,\n",
    "    \"tokenizer_path\": \"models/movie_review_tokenizer.json\",\n",
    "    \"token_ids_path\": \"data/IMDb/mlm_dataset/padded_token_ids.pt\",\n",
    "    \"attention_mask_path\": \"data/IMDb/mlm_dataset/padded_attention_masks.pt\",\n",
    "    \n",
    "    # GPU Optimization\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"mixed_precision\": True,\n",
    "    \"flash_attention\": True,\n",
    "    \"checkpoint_interval\": 2,\n",
    "    \"checkpoint_dir\": \"model_checkpoints\"\n",
    "}\n",
    "\n",
    "print(\"Active device:\", CONFIG[\"device\"])\n",
    "os.makedirs(CONFIG[\"checkpoint_dir\"], exist_ok=True)\n",
    "\n",
    "# Enable FlashAttention if available\n",
    "if CONFIG[\"flash_attention\"] and torch.cuda.is_available():\n",
    "    torch.backends.cuda.enable_flash_sdp(True)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ======================\n",
    "# 1. Load Tokenizer\n",
    "# ======================\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = Tokenizer.from_file(CONFIG[\"tokenizer_path\"])\n",
    "\n",
    "SPECIAL_TOKENS = {\n",
    "    \"pad\": \"[PAD]\",\n",
    "    \"mask\": \"[MASK]\",\n",
    "    \"cls\": \"[CLS]\",\n",
    "    \"sep\": \"[SEP]\"\n",
    "}\n",
    "\n",
    "SPECIAL_IDS = {name: tokenizer.token_to_id(tok) for name, tok in SPECIAL_TOKENS.items()}\n",
    "assert all(v is not None for v in SPECIAL_IDS.values()), \"Missing special tokens!\"\n",
    "\n",
    "# ======================\n",
    "# 2. Dataset and Dynamic Masking\n",
    "# ======================\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, token_ids, attention_masks):\n",
    "        self.encodings = {\n",
    "            'input_ids': token_ids,\n",
    "            'attention_mask': attention_masks\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
    "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx])\n",
    "        }\n",
    "\n",
    "class DynamicMaskingCollator:\n",
    "    def __init__(self, tokenizer, mask_prob=0.15):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_prob = mask_prob\n",
    "        self.special_ids = SPECIAL_IDS\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        inputs = torch.stack([item['input_ids'] for item in batch])\n",
    "        attention_masks = torch.stack([item['attention_mask'] for item in batch])\n",
    "        labels = inputs.clone()\n",
    "        pad_mask = (inputs == self.special_ids[\"pad\"])\n",
    "\n",
    "        # Dynamic masking\n",
    "        mask = torch.rand(inputs.shape) < self.mask_prob\n",
    "        for token_id in self.special_ids.values():\n",
    "            mask &= (inputs != token_id)\n",
    "\n",
    "        labels[~mask] = -100  # Ignore non-masked tokens\n",
    "\n",
    "        # Apply masking (80% [MASK], 10% random, 10% original)\n",
    "        mask_indices = mask.nonzero(as_tuple=True)\n",
    "        rand_vals = torch.rand(mask.sum())\n",
    "        \n",
    "        # 80% [MASK]\n",
    "        mask_80 = (rand_vals < 0.8)\n",
    "        inputs[mask_indices[0][mask_80], mask_indices[1][mask_80]] = self.special_ids[\"mask\"]\n",
    "        \n",
    "        # 10% random token\n",
    "        mask_10 = (rand_vals >= 0.8) & (rand_vals < 0.9)\n",
    "        random_tokens = torch.randint(0, len(self.tokenizer.get_vocab()), (mask_10.sum(),))\n",
    "        inputs[mask_indices[0][mask_10], mask_indices[1][mask_10]] = random_tokens\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs,\n",
    "            'attention_mask': attention_masks,\n",
    "            'labels': labels,\n",
    "            'pad_mask': pad_mask\n",
    "        }\n",
    "\n",
    "# Load data\n",
    "token_ids = torch.load(CONFIG[\"token_ids_path\"]).numpy()\n",
    "attention_masks = torch.load(CONFIG[\"attention_mask_path\"]).numpy()\n",
    "full_dataset = ReviewDataset(token_ids, attention_masks)\n",
    "\n",
    "# Split dataset\n",
    "train_size = int(CONFIG[\"train_ratio\"] * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders with dynamic masking\n",
    "mask_collator = DynamicMaskingCollator(tokenizer, mask_prob=CONFIG[\"mask_prob\"])\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=mask_collator,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    collate_fn=mask_collator\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 3. Model Architecture\n",
    "# ======================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=768):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even positions\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd positions\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(1), :]\n",
    "\n",
    "class MLMTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, CONFIG[\"d_model\"])\n",
    "        self.pos_encoder = PositionalEncoding(CONFIG[\"d_model\"])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=CONFIG[\"d_model\"],\n",
    "            nhead=CONFIG[\"nhead\"],\n",
    "            dim_feedforward=CONFIG[\"dim_feedforward\"],\n",
    "            batch_first=True,\n",
    "            dropout=0.1\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=CONFIG[\"num_layers\"])\n",
    "        self.fc = nn.Linear(CONFIG[\"d_model\"], vocab_size)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer(x, src_key_padding_mask=mask)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ======================\n",
    "# 4. Training Setup\n",
    "# ======================\n",
    "model = MLMTransformer(len(tokenizer.get_vocab())).to(CONFIG[\"device\"])\n",
    "optimizer = AdamW(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler(enabled=CONFIG[\"mixed_precision\"])\n",
    "autocast = torch.amp.autocast(CONFIG[\"device\"], dtype=torch.float16, enabled=CONFIG[\"mixed_precision\"])\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    mask = labels != -100\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "    return accuracy_score(labels[mask].cpu(), preds[mask].cpu())\n",
    "\n",
    "def save_checkpoint(epoch):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict()\n",
    "    }, f\"{CONFIG['checkpoint_dir']}/checkpoint_epoch_{epoch}.pt\")\n",
    "\n",
    "# ======================\n",
    "# 5. Training Loop\n",
    "# ======================\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(CONFIG[\"epochs\"]):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        inputs = batch['input_ids'].to(CONFIG[\"device\"])\n",
    "        labels = batch['labels'].to(CONFIG[\"device\"])\n",
    "        pad_mask = batch['pad_mask'].to(CONFIG[\"device\"])\n",
    "        \n",
    "        with autocast:\n",
    "            outputs = model(inputs, mask=pad_mask)\n",
    "            loss = criterion(outputs.view(-1, len(tokenizer.get_vocab())), labels.view(-1))\n",
    "            loss = loss / CONFIG[\"gradient_accumulation_steps\"]\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % CONFIG[\"gradient_accumulation_steps\"] == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    val_progress = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_progress:\n",
    "            inputs = batch['input_ids'].to(CONFIG[\"device\"])\n",
    "            labels = batch['labels'].to(CONFIG[\"device\"])\n",
    "            pad_mask = batch['pad_mask'].to(CONFIG[\"device\"])\n",
    "            \n",
    "            outputs = model(inputs, mask=pad_mask)\n",
    "            loss = criterion(outputs.view(-1, len(tokenizer.get_vocab())), labels.view(-1))\n",
    "            preds = torch.argmax(outputs, dim=-1)\n",
    "            acc = compute_metrics(preds, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_acc += acc\n",
    "            val_progress.set_postfix({'val_loss': loss.item(), 'acc': acc})\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % CONFIG[\"checkpoint_interval\"] == 0:\n",
    "        save_checkpoint(epoch + 1)\n",
    "    \n",
    "    # Log metrics\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_acc = val_acc / len(val_loader)\n",
    "    \n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    accuracies.append(avg_val_acc)\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Val Accuracy: {avg_val_acc:.4f}\\n\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie_review_mlm",
   "language": "python",
   "name": "movie_review_mlm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
